{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8faa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f912b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loss_function import SaliencyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d94201ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_images(pred_path, thresh_path): \n",
    "\n",
    "    # Open prediction images\n",
    "    for filename in sorted(os.listdir(pred_path)):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(pred_path, filename)\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            # threshold\n",
    "            img_thresh = cv2.threshold(img, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "            new_path = thresh_path+\"/\"+filename\n",
    "\n",
    "            # write images to new path\n",
    "            cv2.imwrite(new_path, img_thresh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b59b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_folder = \"/Users/poojamukund/Documents/Vision Lab/saliency-prediction/3-24-results/predictions\"\n",
    "thresh_folder = \"/Users/poojamukund/Documents/Vision Lab/saliency-prediction/3-24-results/thresholded_predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a523e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "threshold_images(pred_folder, thresh_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2517fc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eem003_8988_binary_mask_cln.png\n",
      "eem003_8988_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 1: tensor([0.1532])\n",
      "NSS loss for image 1: tensor([1.3609])\n",
      "SIM loss for image 1: tensor([0.1199])\n",
      "eem005_8909_binary_mask_cln.png\n",
      "eem005_8909_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 2: tensor([0.0333])\n",
      "NSS loss for image 2: tensor([0.4349])\n",
      "SIM loss for image 2: tensor([0.0376])\n",
      "eem005_9108_binary_mask_cln.png\n",
      "eem005_9108_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 3: tensor([0.0418])\n",
      "NSS loss for image 3: tensor([0.3858])\n",
      "SIM loss for image 3: tensor([0.0484])\n",
      "eem006_9198_binary_mask_cln.png\n",
      "eem006_9198_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 4: tensor([0.1893])\n",
      "NSS loss for image 4: tensor([1.2383])\n",
      "SIM loss for image 4: tensor([0.1744])\n",
      "eem008_8935_binary_mask_cln.png\n",
      "eem008_8935_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 5: tensor([0.0957])\n",
      "NSS loss for image 5: tensor([0.8617])\n",
      "SIM loss for image 5: tensor([0.1028])\n",
      "eem008_9184_binary_mask_cln.png\n",
      "eem008_9184_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 6: tensor([-0.0109])\n",
      "NSS loss for image 6: tensor([-0.1182])\n",
      "SIM loss for image 6: tensor([0.])\n",
      "eem008_9189_binary_mask_cln.png\n",
      "eem008_9189_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 7: tensor([0.0022])\n",
      "NSS loss for image 7: tensor([0.0143])\n",
      "SIM loss for image 7: tensor([0.0020])\n",
      "eem008_9238_binary_mask_cln.png\n",
      "eem008_9238_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 8: tensor([0.0690])\n",
      "NSS loss for image 8: tensor([0.9731])\n",
      "SIM loss for image 8: tensor([0.0483])\n",
      "eem009_073_OD_binary_mask_cln.png\n",
      "eem009_073_OD_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 9: tensor([0.0293])\n",
      "NSS loss for image 9: tensor([0.1671])\n",
      "SIM loss for image 9: tensor([0.0268])\n",
      "eem009_085_OD_binary_mask_cln.png\n",
      "eem009_085_OD_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 10: tensor([-0.0032])\n",
      "NSS loss for image 10: tensor([-0.0136])\n",
      "SIM loss for image 10: tensor([0.0156])\n",
      "eem010_127_OD_binary_mask_cln.png\n",
      "eem010_127_OD_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 11: tensor([0.0581])\n",
      "NSS loss for image 11: tensor([0.2457])\n",
      "SIM loss for image 11: tensor([0.0608])\n",
      "eem011_019_OS_binary_mask_cln.png\n",
      "eem011_019_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 12: tensor([0.1453])\n",
      "NSS loss for image 12: tensor([0.6835])\n",
      "SIM loss for image 12: tensor([0.0848])\n",
      "eem011_059_OS_binary_mask_cln.png\n",
      "eem011_059_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 13: tensor([0.1008])\n",
      "NSS loss for image 13: tensor([0.5261])\n",
      "SIM loss for image 13: tensor([0.0634])\n",
      "eem011_087_OS_binary_mask_cln.png\n",
      "eem011_087_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 14: tensor([0.0204])\n",
      "NSS loss for image 14: tensor([0.1438])\n",
      "SIM loss for image 14: tensor([0.0266])\n",
      "eem013_018_OS_binary_mask_cln.png\n",
      "eem013_018_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 15: tensor([0.0642])\n",
      "NSS loss for image 15: tensor([0.2474])\n",
      "SIM loss for image 15: tensor([0.0249])\n",
      "eem013_028_OS_binary_mask_cln.png\n",
      "eem013_028_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 16: tensor([0.1227])\n",
      "NSS loss for image 16: tensor([0.7864])\n",
      "SIM loss for image 16: tensor([0.0944])\n",
      "eem013_078_OS_binary_mask_cln.png\n",
      "eem013_078_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 17: tensor([0.1086])\n",
      "NSS loss for image 17: tensor([0.7560])\n",
      "SIM loss for image 17: tensor([0.0714])\n",
      "eem015_009_OD_binary_mask_cln.png\n",
      "eem015_009_OD_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 18: tensor([0.0687])\n",
      "NSS loss for image 18: tensor([0.8740])\n",
      "SIM loss for image 18: tensor([0.0491])\n",
      "eem015_059_OS_binary_mask_cln.png\n",
      "eem015_059_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 19: tensor([-0.0134])\n",
      "NSS loss for image 19: tensor([-0.1013])\n",
      "SIM loss for image 19: tensor([0.])\n",
      "eem015_068_OD_binary_mask_cln.png\n",
      "eem015_068_OD_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 20: tensor([0.1525])\n",
      "NSS loss for image 20: tensor([2.9816])\n",
      "SIM loss for image 20: tensor([0.0663])\n",
      "eem015_081_OD_binary_mask_cln.png\n",
      "eem015_081_OD_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 21: tensor([-0.0118])\n",
      "NSS loss for image 21: tensor([-0.1122])\n",
      "SIM loss for image 21: tensor([0.])\n",
      "eem016_047_OS_binary_mask_cln.png\n",
      "eem016_047_OS_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 22: tensor([-0.0138])\n",
      "NSS loss for image 22: tensor([-0.0757])\n",
      "SIM loss for image 22: tensor([0.0024])\n",
      "eem016_093_OD_binary_mask_cln.png\n",
      "eem016_093_OD_original_prediction.png\n",
      "(1, 288, 384)\n",
      "0\n",
      "0\n",
      "Correlation for image 23: tensor([0.0073])\n",
      "NSS loss for image 23: tensor([0.0476])\n",
      "SIM loss for image 23: tensor([0.0171])\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder_path, resize_shape=None):\n",
    "    images = []\n",
    "    images_name = []\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            img = Image.open(img_path).convert('L')\n",
    "            \n",
    "            \n",
    "            if resize_shape is not None:\n",
    "                img = cv2.resize(img, resize_shape)\n",
    "            images.append(img)\n",
    "            images_name.append(filename)\n",
    "    return images, images_name\n",
    "\n",
    "\n",
    "gt_folder = \"/Users/poojamukund/Documents/Vision Lab/saliency-prediction/3-24-results/gt\"\n",
    "pred_folder = \"/Users/poojamukund/Documents/Vision Lab/saliency-prediction/3-24-results/thresholded_predictions\"\n",
    "\n",
    "\n",
    "\n",
    "gt_images,filename_gt  = load_images_from_folder(gt_folder)\n",
    "pred_images,filename_pred = load_images_from_folder(pred_folder)\n",
    "CC=[]\n",
    "NSS =[]\n",
    "BCE=[]\n",
    "KL=[]\n",
    "SIM=[]\n",
    "accuracy = SaliencyLoss()\n",
    "for i in range(len(gt_images)):\n",
    "    gt_image= gt_images[i]\n",
    "    pred_image = pred_images[i]\n",
    "    print(filename_gt[i])\n",
    "    print(filename_pred[i])\n",
    "\n",
    "    gt_image = np.expand_dims(gt_image, axis=0)\n",
    "    print(gt_image.shape)\n",
    "    pred_image= np.expand_dims(pred_image, axis=0)\n",
    "    print(np.min(pred_image))\n",
    "    print(np.min(gt_image))\n",
    "    correlation = accuracy(torch.from_numpy(pred_image/255).float(),torch.from_numpy(gt_image/255).float(),loss_type='cc')\n",
    "    CC.append(correlation)\n",
    "#     bce = loss_fn(torch.from_numpy(pred_image/255).float(),torch.from_numpy(gt_image/255).float())\n",
    "#     BCE.append(bce)\n",
    "    nss = accuracy(torch.from_numpy(pred_image/255).float(),torch.from_numpy(gt_image/255).float(),loss_type='nss')\n",
    "    NSS.append(nss)\n",
    "    kl = accuracy(torch.from_numpy(pred_image/255).float(),torch.from_numpy(gt_image/255).float(),loss_type='kldiv')\n",
    "    KL.append(kl)\n",
    "    sim = accuracy(torch.from_numpy(pred_image/255).float(),torch.from_numpy(gt_image/255).float(),loss_type='sim')\n",
    "    SIM.append(sim)\n",
    "    print(\"Correlation for image {}: {}\".format(i+1, correlation))\n",
    "   # print(\"BCE loss for image {}: {}\".format(i+1, bce))\n",
    "    print(\"NSS loss for image {}: {}\".format(i+1, nss))\n",
    "    print(\"SIM loss for image {}: {}\".format(i+1, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74a5189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for test image: tensor([0.0613])\n",
      "NSS loss for test image: tensor([0.5351])\n",
      "KL for test image: tensor([26.4936])\n",
      "Similarity for test image: tensor([0.0494])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean\n",
    "print(\"Correlation for test image: {}\".format(sum(CC) / len(CC)))\n",
    "print(\"NSS loss for test image: {}\".format(sum(NSS) / len(NSS)))\n",
    "print(\"KL for test image: {}\".format( sum(KL) / len(KL)))\n",
    "print(\"Similarity for test image: {}\".format( sum(SIM) / len(SIM)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
